{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac38e61",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è Acceso a Datos NASA GES DISC con Python\n",
    "\n",
    "## Descripci√≥n General\n",
    "\n",
    "Este notebook demuestra c√≥mo acceder a datos de NASA GES DISC (Goddard Earth Sciences Data and Information Services Center) usando Python y la librer√≠a oficial `earthaccess` recomendada por NASA.\n",
    "\n",
    "### Caracter√≠sticas principales:\n",
    "- ‚úÖ **Autenticaci√≥n moderna** usando `earthaccess`\n",
    "- ‚úÖ **B√∫squeda inteligente** de datasets por coordenadas, fechas y tipos\n",
    "- ‚úÖ **Descarga directa** desde la nube de NASA\n",
    "- ‚úÖ **Visualizaci√≥n** de datos clim√°ticos\n",
    "- ‚úÖ **Compatibilidad** con m√∫ltiples formatos (NetCDF, HDF)\n",
    "\n",
    "### Datasets soportados:\n",
    "- **IMERG**: Precipitaci√≥n diaria y mensual\n",
    "- **MERRA-2**: Datos atmosf√©ricos\n",
    "- **MODIS**: Temperatura superficial terrestre\n",
    "- **GPM**: Datos de precipitaci√≥n\n",
    "\n",
    "### Referencias:\n",
    "- [Tutoriales oficiales NASA GES DISC](https://github.com/nasa/gesdisc-tutorials)\n",
    "- [Documentaci√≥n earthaccess](https://earthaccess.readthedocs.io/)\n",
    "- [C√≥mo acceder a datos GES DISC con Python](https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Access%20GES%20DISC%20Data%20Using%20Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199ef0a",
   "metadata": {},
   "source": [
    "## 1. üì¶ Importar Librer√≠as Requeridas\n",
    "\n",
    "Primero instalamos e importamos todas las librer√≠as necesarias para acceder a los datos de NASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar earthaccess si no est√° disponible\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import earthaccess\n",
    "    print(\"‚úÖ earthaccess ya est√° instalado\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Instalando earthaccess...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"earthaccess\"])\n",
    "    import earthaccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42640d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las librer√≠as necesarias\n",
    "import earthaccess\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Configurar visualizaci√≥n\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas exitosamente:\")\n",
    "print(f\"   - earthaccess: {earthaccess.__version__}\")\n",
    "print(f\"   - xarray: {xr.__version__}\")\n",
    "print(f\"   - matplotlib: disponible\")\n",
    "print(f\"   - cartopy: disponible\")\n",
    "print(f\"   - pandas: {pd.__version__}\")\n",
    "print(f\"   - numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2929b",
   "metadata": {},
   "source": [
    "## 2. üîê Configurar Credenciales de Autenticaci√≥n\n",
    "\n",
    "La autenticaci√≥n con NASA Earthdata es necesaria para acceder a los datos. `earthaccess` maneja esto autom√°ticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar credenciales NASA Earthdata\n",
    "# Opci√≥n 1: Usar credenciales ya guardadas en .netrc\n",
    "try:\n",
    "    auth = earthaccess.login(strategy=\"netrc\")\n",
    "    if auth.authenticated:\n",
    "        print(\"‚úÖ Autenticado usando archivo .netrc existente\")\n",
    "    else:\n",
    "        raise Exception(\"No se pudo autenticar con .netrc\")\n",
    "except:\n",
    "    # Opci√≥n 2: Autenticaci√≥n interactiva (pedir√° usuario y contrase√±a)\n",
    "    print(\"üîê Configurando autenticaci√≥n interactiva...\")\n",
    "    auth = earthaccess.login(strategy=\"interactive\", persist=True)\n",
    "    \n",
    "    if auth.authenticated:\n",
    "        print(\"‚úÖ Autenticaci√≥n exitosa! Credenciales guardadas en .netrc\")\n",
    "    else:\n",
    "        print(\"‚ùå Error en la autenticaci√≥n. Verifica tus credenciales.\")\n",
    "        \n",
    "# Mostrar informaci√≥n de autenticaci√≥n\n",
    "if auth.authenticated:\n",
    "    print(\"üéØ Listo para acceder a datos NASA Earthdata\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Necesitas credenciales v√°lidas de https://urs.earthdata.nasa.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8087e",
   "metadata": {},
   "source": [
    "## 3. ‚öôÔ∏è Configurar Par√°metros de Acceso a Datos\n",
    "\n",
    "Definimos los par√°metros para buscar y acceder a diferentes tipos de datos clim√°ticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de datasets y par√°metros\n",
    "datasets_config = {\n",
    "    'IMERG_DAILY': {\n",
    "        'short_name': 'GPM_3IMERGHH',  # Datos IMERG de precipitaci√≥n\n",
    "        'doi': '10.5067/GPM/IMERGDF/DAY/07',  # DOI para datos diarios\n",
    "        'description': 'Precipitaci√≥n diaria GPM IMERG',\n",
    "        'variables': ['precipitationCal', 'lat', 'lon', 'time']\n",
    "    },\n",
    "    'MERRA2_SLV': {\n",
    "        'short_name': 'M2T1NXSLV',  # MERRA-2 Single Level Variables\n",
    "        'version': '5.12.4',\n",
    "        'description': 'MERRA-2 Variables de Superficie',\n",
    "        'variables': ['T2M', 'QV2M', 'PS', 'U10M', 'V10M']  # Temperatura, humedad, presi√≥n, viento\n",
    "    }\n",
    "}\n",
    "\n",
    "# Coordenadas de inter√©s (Pen√≠nsula Ib√©rica)\n",
    "locations = {\n",
    "    'Madrid': {'lat': 40.4168, 'lon': -3.7038},\n",
    "    'Barcelona': {'lat': 41.3851, 'lon': 2.1734},\n",
    "    'Valencia': {'lat': 39.4699, 'lon': -0.3763},\n",
    "    'Sevilla': {'lat': 37.3891, 'lon': -5.9845}\n",
    "}\n",
    "\n",
    "# Configurar √°rea geogr√°fica y temporal\n",
    "bbox = (-10, 35, 5, 45)  # Pen√≠nsula Ib√©rica (oeste, sur, este, norte)\n",
    "fecha_inicio = '2024-03-01'  # Cambiar por fecha de inter√©s\n",
    "fecha_fin = '2024-03-03'     # Per√≠odo de 3 d√≠as para prueba\n",
    "\n",
    "print(\"üó∫Ô∏è  Configuraci√≥n espacial:\")\n",
    "print(f\"   Bounding Box: {bbox} (Pen√≠nsula Ib√©rica)\")\n",
    "print(f\"   Ciudades: {list(locations.keys())}\")\n",
    "\n",
    "print(\"üìÖ Configuraci√≥n temporal:\")\n",
    "print(f\"   Fecha inicio: {fecha_inicio}\")\n",
    "print(f\"   Fecha fin: {fecha_fin}\")\n",
    "\n",
    "print(\"üìä Datasets configurados:\")\n",
    "for key, config in datasets_config.items():\n",
    "    print(f\"   - {key}: {config['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebbdeff",
   "metadata": {},
   "source": [
    "## 4. üîç Buscar y Descargar Archivos de Datos\n",
    "\n",
    "Usamos `earthaccess` para buscar datos disponibles seg√∫n nuestros criterios espaciales y temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para buscar granulos de datos\n",
    "def search_granules(dataset_name, temporal_range, bbox=None, max_results=5):\n",
    "    \"\"\"\n",
    "    Buscar granulos usando earthaccess\n",
    "    \"\"\"\n",
    "    config = datasets_config[dataset_name]\n",
    "    \n",
    "    search_params = {\n",
    "        'temporal': temporal_range,\n",
    "        'count': max_results\n",
    "    }\n",
    "    \n",
    "    # A√±adir par√°metros espec√≠ficos del dataset\n",
    "    if 'short_name' in config:\n",
    "        search_params['short_name'] = config['short_name']\n",
    "    if 'version' in config:\n",
    "        search_params['version'] = config['version']\n",
    "    if 'doi' in config:\n",
    "        search_params['doi'] = config['doi']\n",
    "    if bbox:\n",
    "        search_params['bounding_box'] = bbox\n",
    "    \n",
    "    print(f\"üîç Buscando {config['description']}...\")\n",
    "    print(f\"   Par√°metros: {search_params}\")\n",
    "    \n",
    "    try:\n",
    "        results = earthaccess.search_data(**search_params)\n",
    "        print(f\"‚úÖ Encontrados {len(results)} granulos\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en b√∫squeda: {e}\")\n",
    "        return []\n",
    "\n",
    "# Buscar datos MERRA-2 (m√°s probable que existan)\n",
    "print(\"=\" * 60)\n",
    "granules_merra2 = search_granules('MERRA2_SLV', (fecha_inicio, fecha_fin), bbox)\n",
    "\n",
    "# Mostrar informaci√≥n de los granulos encontrados\n",
    "if granules_merra2:\n",
    "    print(f\"\\\\nüìÅ Informaci√≥n del primer granulo encontrado:\")\n",
    "    first_granule = granules_merra2[0]\n",
    "    print(f\"   ID: {first_granule['meta']['concept-id']}\")\n",
    "    print(f\"   Nombre: {first_granule['umm']['GranuleUR']}\")\n",
    "    print(f\"   Tama√±o: {first_granule.size()} MB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron granulos para el per√≠odo especificado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n 1: Streaming directo (recomendado para an√°lisis r√°pido)\n",
    "def stream_data(granules, variables=None):\n",
    "    \"\"\"\n",
    "    Hace streaming de datos directamente a xarray sin descargar\n",
    "    \"\"\"\n",
    "    print(\"üåä Streaming datos a memoria...\")\n",
    "    try:\n",
    "        # Abrir archivos usando earthaccess (streaming directo desde la nube)\n",
    "        files = earthaccess.open(granules)\n",
    "        \n",
    "        # Cargar en xarray\n",
    "        ds = xr.open_mfdataset(files, engine='h5netcdf', combine='by_coords')\n",
    "        \n",
    "        print(f\"‚úÖ Dataset cargado: {ds.sizes}\")\n",
    "        return ds\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en streaming: {e}\")\n",
    "        return None\n",
    "\n",
    "# Opci√≥n 2: Descarga local (para archivos grandes o an√°lisis offline)\n",
    "def download_data(granules, local_path='./data'):\n",
    "    \"\"\"\n",
    "    Descarga archivos localmente\n",
    "    \"\"\"\n",
    "    print(f\"üíæ Descargando a {local_path}...\")\n",
    "    try:\n",
    "        downloaded_files = earthaccess.download(granules, local_path=local_path)\n",
    "        print(f\"‚úÖ Descargados {len(downloaded_files)} archivos\")\n",
    "        return downloaded_files\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en descarga: {e}\")\n",
    "        return []\n",
    "\n",
    "# Probar streaming si hay datos disponibles\n",
    "if granules_merra2:\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"üöÄ PROBANDO STREAMING DE DATOS...\")\n",
    "    \n",
    "    # Usar solo el primer granulo para la prueba\n",
    "    test_granules = granules_merra2[:1]\n",
    "    \n",
    "    dataset = stream_data(test_granules)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        print(f\"\\\\nüìä Informaci√≥n del dataset:\")\n",
    "        print(f\"   Dimensiones: {dict(dataset.sizes)}\")\n",
    "        print(f\"   Variables disponibles: {list(dataset.data_vars.keys())}\")\n",
    "        print(f\"   Coordenadas: {list(dataset.coords.keys())}\")\n",
    "else:\n",
    "    print(\"\\\\n‚è≠Ô∏è Saltando streaming - no hay granulos disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc24444",
   "metadata": {},
   "source": [
    "## 5. üìã Cargar e Inspeccionar Datos\n",
    "\n",
    "Analizamos la estructura y metadatos de los datos cargados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e43247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para inspeccionar el dataset\n",
    "def inspect_dataset(ds, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Inspecciona un dataset de xarray y muestra informaci√≥n √∫til\n",
    "    \"\"\"\n",
    "    print(f\"\\\\nüîç INSPECCI√ìN DE {dataset_name.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Informaci√≥n general\n",
    "    print(f\"üìè Dimensiones: {dict(ds.sizes)}\")\n",
    "    print(f\"üìä Variables de datos: {len(ds.data_vars)}\")\n",
    "    print(f\"üó∫Ô∏è  Coordenadas: {len(ds.coords)}\")\n",
    "    \n",
    "    # Detalles de variables importantes\n",
    "    print(\"\\\\nüìã Variables principales:\")\n",
    "    for var_name, var in ds.data_vars.items():\n",
    "        if len(var.dims) >= 2:  # Solo variables multidimensionales\n",
    "            attrs = dict(var.attrs) if var.attrs else {}\n",
    "            units = attrs.get('units', 'N/A')\n",
    "            long_name = attrs.get('long_name', 'N/A')\n",
    "            print(f\"   ‚Ä¢ {var_name}: {var.dims} | {units}\")\n",
    "            if long_name != 'N/A':\n",
    "                print(f\"     ‚îî‚îÄ {long_name}\")\n",
    "    \n",
    "    # Informaci√≥n temporal\n",
    "    if 'time' in ds.coords:\n",
    "        time_coord = ds.coords['time']\n",
    "        print(f\"\\\\n‚è∞ Rango temporal:\")\n",
    "        print(f\"   Inicio: {pd.to_datetime(time_coord.min().values)}\")\n",
    "        print(f\"   Fin: {pd.to_datetime(time_coord.max().values)}\")\n",
    "        print(f\"   Pasos: {len(time_coord)}\")\n",
    "    \n",
    "    # Informaci√≥n espacial\n",
    "    if 'lat' in ds.coords and 'lon' in ds.coords:\n",
    "        lat_range = (float(ds.lat.min()), float(ds.lat.max()))\n",
    "        lon_range = (float(ds.lon.min()), float(ds.lon.max()))\n",
    "        print(f\"\\\\nüåç Cobertura espacial:\")\n",
    "        print(f\"   Latitud: {lat_range[0]:.2f}¬∞ a {lat_range[1]:.2f}¬∞\")\n",
    "        print(f\"   Longitud: {lon_range[0]:.2f}¬∞ a {lon_range[1]:.2f}¬∞\")\n",
    "        print(f\"   Resoluci√≥n: ~{abs(float(ds.lat[1] - ds.lat[0])):.3f}¬∞ lat, ~{abs(float(ds.lon[1] - ds.lon[0])):.3f}¬∞ lon\")\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Inspeccionar dataset si est√° disponible\n",
    "if 'dataset' in locals() and dataset is not None:\n",
    "    inspect_dataset(dataset, \"MERRA-2\")\n",
    "    \n",
    "    # Ejemplo de extracci√≥n de datos para una ubicaci√≥n espec√≠fica\n",
    "    if 'lat' in dataset.coords and 'lon' in dataset.coords:\n",
    "        print(\"\\\\nüéØ EXTRAYENDO DATOS PARA MADRID\")\n",
    "        madrid_coords = locations['Madrid']\n",
    "        \n",
    "        # Seleccionar punto m√°s cercano a Madrid\n",
    "        madrid_data = dataset.sel(\n",
    "            lat=madrid_coords['lat'], \n",
    "            lon=madrid_coords['lon'], \n",
    "            method='nearest'\n",
    "        )\n",
    "        \n",
    "        print(f\"   Coordenadas seleccionadas: {float(madrid_data.lat.values):.2f}¬∞, {float(madrid_data.lon.values):.2f}¬∞\")\n",
    "        \n",
    "        # Mostrar variables disponibles\n",
    "        if 'T2M' in madrid_data.data_vars:\n",
    "            temp_data = madrid_data['T2M']\n",
    "            print(f\"   Temperatura (T2M): {float(temp_data.mean()):.1f} K ({float(temp_data.mean()) - 273.15:.1f}¬∞C)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è No hay dataset cargado para inspeccionar\")\n",
    "    \n",
    "    # Crear datos de ejemplo para demostraci√≥n\n",
    "    print(\"\\\\nüé¨ Creando datos de ejemplo para demostraci√≥n...\")\n",
    "    \n",
    "    # Generar datos sint√©ticos\n",
    "    times = pd.date_range('2024-03-01', '2024-03-03', freq='1D')\n",
    "    lats = np.linspace(35, 45, 20)  # Pen√≠nsula Ib√©rica\n",
    "    lons = np.linspace(-10, 5, 30)\n",
    "    \n",
    "    # Crear datos de temperatura sint√©ticos\n",
    "    temp_data = 15 + 10 * np.random.random((len(times), len(lats), len(lons)))\n",
    "    \n",
    "    # Crear dataset de ejemplo\n",
    "    dataset = xr.Dataset({\n",
    "        'temperature': (['time', 'lat', 'lon'], temp_data, {\n",
    "            'long_name': 'Temperatura del aire a 2 metros (ejemplo)',\n",
    "            'units': '¬∞C'\n",
    "        })\n",
    "    }, coords={\n",
    "        'time': times,\n",
    "        'lat': lats,\n",
    "        'lon': lons\n",
    "    })\n",
    "    \n",
    "    print(\"‚úÖ Dataset de ejemplo creado\")\n",
    "    inspect_dataset(dataset, \"Ejemplo Sint√©tico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4fe73",
   "metadata": {},
   "source": [
    "## 6. üìä Procesar y Visualizar Datos\n",
    "\n",
    "Creamos visualizaciones de los datos clim√°ticos usando matplotlib y cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para crear mapas con proyecci√≥n geogr√°fica\n",
    "def plot_spatial_data(ds, variable, time_index=0, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Crea un mapa de datos espaciales usando cartopy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Seleccionar variable y tiempo\n",
    "        if variable in ds.data_vars:\n",
    "            data = ds[variable]\n",
    "        else:\n",
    "            # Usar la primera variable disponible\n",
    "            data = ds[list(ds.data_vars.keys())[0]]\n",
    "            variable = list(ds.data_vars.keys())[0]\n",
    "        \n",
    "        # Seleccionar tiempo si existe\n",
    "        if 'time' in data.dims and len(data.time) > time_index:\n",
    "            data = data.isel(time=time_index)\n",
    "            time_str = pd.to_datetime(data.time.values).strftime('%Y-%m-%d')\n",
    "            title = f\"{title_prefix}{variable} - {time_str}\"\n",
    "        else:\n",
    "            title = f\"{title_prefix}{variable}\"\n",
    "        \n",
    "        # Crear figura con proyecci√≥n\n",
    "        fig = plt.figure(figsize=(14, 10))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        \n",
    "        # A√±adir caracter√≠sticas geogr√°ficas\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.add_feature(cfeature.BORDERS)\n",
    "        ax.add_feature(cfeature.LAND, alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, alpha=0.3)\n",
    "        \n",
    "        # Plot principal\n",
    "        im = data.plot(\n",
    "            ax=ax, \n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap='viridis',\n",
    "            add_colorbar=False\n",
    "        )\n",
    "        \n",
    "        # A√±adir colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "        units = data.attrs.get('units', '')\n",
    "        cbar.set_label(f\"{variable} {units}\")\n",
    "        \n",
    "        # A√±adir ciudades\n",
    "        for city, coords in locations.items():\n",
    "            ax.plot(coords['lon'], coords['lat'], 'ro', markersize=8, transform=ccrs.PlateCarree())\n",
    "            ax.text(coords['lon'], coords['lat'], f'  {city}', \n",
    "                   transform=ccrs.PlateCarree(), fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Configurar extent para Espa√±a\n",
    "        ax.set_extent([-12, 6, 34, 46], ccrs.PlateCarree())\n",
    "        ax.gridlines(draw_labels=True, alpha=0.5)\n",
    "        \n",
    "        plt.title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en visualizaci√≥n: {e}\")\n",
    "        # Fallback: plot simple sin proyecci√≥n\n",
    "        if variable in ds.data_vars:\n",
    "            data = ds[variable]\n",
    "            if 'time' in data.dims:\n",
    "                data = data.isel(time=0)\n",
    "            data.plot(figsize=(12, 6))\n",
    "            plt.title(f\"{title_prefix}{variable}\")\n",
    "            plt.show()\n",
    "\n",
    "# Funci√≥n para series temporales\n",
    "def plot_time_series(ds, location_name, variables=None):\n",
    "    \"\"\"\n",
    "    Crea gr√°ficos de series temporales para una ubicaci√≥n\n",
    "    \"\"\"\n",
    "    if location_name not in locations:\n",
    "        print(f\"‚ùå Ubicaci√≥n '{location_name}' no encontrada\")\n",
    "        return\n",
    "    \n",
    "    coords = locations[location_name]\n",
    "    \n",
    "    try:\n",
    "        # Seleccionar punto m√°s cercano\n",
    "        if 'lat' in ds.coords and 'lon' in ds.coords:\n",
    "            point_data = ds.sel(lat=coords['lat'], lon=coords['lon'], method='nearest')\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se encontraron coordenadas lat/lon\")\n",
    "            return\n",
    "        \n",
    "        # Seleccionar variables\n",
    "        if variables is None:\n",
    "            variables = list(point_data.data_vars.keys())[:3]  # Primeras 3 variables\n",
    "        \n",
    "        # Crear subplots\n",
    "        fig, axes = plt.subplots(len(variables), 1, figsize=(12, 4*len(variables)))\n",
    "        if len(variables) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        fig.suptitle(f'Series Temporales - {location_name}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        for i, var in enumerate(variables):\n",
    "            if var in point_data.data_vars:\n",
    "                data = point_data[var]\n",
    "                \n",
    "                if 'time' in data.dims:\n",
    "                    data.plot(ax=axes[i])\n",
    "                    axes[i].set_title(f\"{var} ({data.attrs.get('units', '')})\")\n",
    "                    axes[i].grid(True, alpha=0.3)\n",
    "                else:\n",
    "                    axes[i].text(0.5, 0.5, f'Variable {var}\\\\nSin dimensi√≥n temporal', \n",
    "                               ha='center', va='center', transform=axes[i].transAxes)\n",
    "                    axes[i].set_title(f\"{var} (valor: {float(data.values):.2f})\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en serie temporal: {e}\")\n",
    "\n",
    "# Visualizar datos si est√°n disponibles\n",
    "if 'dataset' in locals() and dataset is not None:\n",
    "    print(\"üé® CREANDO VISUALIZACIONES...\")\n",
    "    \n",
    "    # Mapa espacial\n",
    "    try:\n",
    "        plot_spatial_data(dataset, list(dataset.data_vars.keys())[0], title_prefix=\"NASA GES DISC - \")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en mapa espacial: {e}\")\n",
    "    \n",
    "    # Serie temporal para Madrid\n",
    "    try:\n",
    "        plot_time_series(dataset, 'Madrid', list(dataset.data_vars.keys())[:2])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en serie temporal: {e}\")\n",
    "    \n",
    "    print(\"‚úÖ Visualizaciones completadas\")\n",
    "else:\n",
    "    print(\"üìä No hay dataset disponible para visualizar\")\n",
    "    print(\"üí° Ejecuta las celdas anteriores para cargar datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae22a40",
   "metadata": {},
   "source": [
    "## üéØ Ejemplo Pr√°ctico: An√°lisis Completo\n",
    "\n",
    "Ahora combinamos todo lo anterior en un flujo de trabajo completo para analizar datos clim√°ticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56591cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis completo: Buscar, cargar y visualizar datos\n",
    "def complete_analysis(dataset_type='MERRA2_SLV', region='spain', days=3):\n",
    "    \"\"\"\n",
    "    Flujo de trabajo completo para an√°lisis de datos NASA\n",
    "    \"\"\"\n",
    "    print(\"üöÄ INICIANDO AN√ÅLISIS COMPLETO DE DATOS NASA GES DISC\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Configurar par√°metros\n",
    "    end_date = datetime.now() - timedelta(days=30)  # Datos de hace 1 mes (m√°s probable que existan)\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    temporal_range = (start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    print(f\"üìÖ Periodo de an√°lisis: {temporal_range[0]} a {temporal_range[1]}\")\n",
    "    print(f\"üó∫Ô∏è  Regi√≥n: {region}\")\n",
    "    print(f\"üìä Dataset: {datasets_config[dataset_type]['description']}\")\n",
    "    \n",
    "    # 2. Buscar datos\n",
    "    print(\"\\\\nüîç PASO 1: B√∫squeda de granulos...\")\n",
    "    granules = search_granules(dataset_type, temporal_range, bbox, max_results=3)\n",
    "    \n",
    "    if not granules:\n",
    "        print(\"‚ùå No se encontraron datos para el per√≠odo especificado\")\n",
    "        print(\"üí° Sugerencias:\")\n",
    "        print(\"   - Prueba con fechas m√°s antiguas\")\n",
    "        print(\"   - Verifica tu autenticaci√≥n\")\n",
    "        print(\"   - Cambia el tipo de dataset\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Cargar datos\n",
    "    print(\"\\\\nüåä PASO 2: Carga de datos...\")\n",
    "    ds = stream_data(granules[:2])  # Usar solo 2 granulos para eficiencia\n",
    "    \n",
    "    if ds is None:\n",
    "        print(\"‚ùå Error al cargar datos\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Procesar y analizar\n",
    "    print(\"\\\\nüìã PASO 3: An√°lisis de datos...\")\n",
    "    inspect_dataset(ds, datasets_config[dataset_type]['description'])\n",
    "    \n",
    "    # 5. Crear visualizaciones\n",
    "    print(\"\\\\nüé® PASO 4: Visualizaciones...\")\n",
    "    \n",
    "    # Mapa espacial\n",
    "    variable_list = list(ds.data_vars.keys())\n",
    "    if variable_list:\n",
    "        plot_spatial_data(ds, variable_list[0], title_prefix=\"NASA - \")\n",
    "    \n",
    "    # Series temporales para ciudades principales\n",
    "    for city in ['Madrid', 'Barcelona']:\n",
    "        try:\n",
    "            plot_time_series(ds, city, variable_list[:1])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è No se pudo crear serie temporal para {city}: {e}\")\n",
    "    \n",
    "    print(\"\\\\n‚úÖ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "    return ds\n",
    "\n",
    "# Ejecutar an√°lisis completo\n",
    "try:\n",
    "    result_dataset = complete_analysis()\n",
    "    \n",
    "    if result_dataset is not None:\n",
    "        print(\"\\\\nüéä ¬°An√°lisis exitoso!\")\n",
    "        print(\"üíæ El dataset est√° disponible como 'result_dataset'\")\n",
    "        print(\"üîÑ Puedes modificar fechas y volver a ejecutar\")\n",
    "    else:\n",
    "        print(\"\\\\n‚ö†Ô∏è An√°lisis no completado\")\n",
    "        print(\"üîß Revisa configuraci√≥n y autenticaci√≥n\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en an√°lisis: {e}\")\n",
    "    print(\"üõ†Ô∏è Verifica tu conexi√≥n a internet y credenciales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ce6d8",
   "metadata": {},
   "source": [
    "## üîó Recursos Adicionales y Pr√≥ximos Pasos\n",
    "\n",
    "### üìö Documentaci√≥n y Tutoriales\n",
    "- [Tutoriales oficiales NASA GES DISC](https://github.com/nasa/gesdisc-tutorials)\n",
    "- [Documentaci√≥n earthaccess](https://earthaccess.readthedocs.io/)\n",
    "- [Gu√≠a de acceso a datos GES DISC](https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Access%20GES%20DISC%20Data%20Using%20Python)\n",
    "\n",
    "### üõ†Ô∏è Funcionalidades Avanzadas\n",
    "- **OPeNDAP**: Acceso directo a subconjuntos de datos sin descarga completa\n",
    "- **Cloud Computing**: Procesamiento en AWS junto a los datos\n",
    "- **Bulk Downloads**: Descarga masiva de series temporales largas\n",
    "- **API Subsetting**: Extracci√≥n espec√≠fica por regiones y variables\n",
    "\n",
    "### üí° Casos de Uso Comunes\n",
    "- **An√°lisis climatol√≥gico**: Series temporales de precipitaci√≥n y temperatura\n",
    "- **Validaci√≥n de modelos**: Comparaci√≥n con datos observacionales\n",
    "- **Estudios de impacto**: An√°lisis de eventos extremos\n",
    "- **Monitoreo ambiental**: Seguimiento de cambios a largo plazo\n",
    "\n",
    "### ‚ö° Optimizaci√≥n de Rendimiento\n",
    "- Usa `bounding_box` para limitar la regi√≥n de inter√©s\n",
    "- Limita el rango temporal para reducir volumen de datos\n",
    "- Considera usar `streaming` en lugar de descarga para an√°lisis exploratorio\n",
    "- Aprovecha el paralelismo de `dask` para datasets grandes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
